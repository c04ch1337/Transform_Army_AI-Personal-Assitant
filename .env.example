# LLM Provider API Keys
# Copy this file to .env (for Docker) or .env.local (for local development)
# Set the API key for your chosen provider:

# OpenAI (https://platform.openai.com/api-keys)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic (https://console.anthropic.com/)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenRouter (https://openrouter.ai/keys)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Ollama (Local - usually no key needed)
# OLLAMA_API_KEY=

# LMStudio (Local - usually no key needed, default: http://localhost:1234)
# LMSTUDIO_API_KEY=

# Local LLM (Custom local endpoint)
# LOCAL_LLM_API_KEY=optional_api_key_if_required
# LOCAL_LLM_ENDPOINT=http://localhost:8000/v1/chat/completions
